---
title: Adaptive multi-fidelity optimization with fast learning rates
abstract: In multi-fidelity optimization, biased approximations of varying costs of
  the target function are available. This paper studies the problem of optimizing
  a locally smooth function with a limited budget, where the learner has to make a
  tradeoff between the cost and the bias of these approximations. We first prove lower
  bounds for the simple regret under different assumptions on the fidelities, based
  on a cost-to-bias function. We then present the Kometo algorithm which achieves,
  with additional logarithmic factors, the same rates without any knowledge of the
  function smoothness and fidelity assumptions, and improves previously proven guarantees.
  We finally empirically show that our algorithm outperforms previous multi-fidelity
  optimization methods without the knowledge of problem-dependent parameters.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: fiegel20a
month: 0
tex_title: Adaptive multi-fidelity optimization with fast learning rates
firstpage: 3493
lastpage: 3502
page: 3493-3502
order: 3493
cycles: false
bibtex_author: Fiegel, C\^ome and Gabillon, Victor and Valko, Michal
author:
- given: CÃ´me
  family: Fiegel
- given: Victor
  family: Gabillon
- given: Michal
  family: Valko
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/fiegel20a/fiegel20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/fiegel20a/fiegel20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
