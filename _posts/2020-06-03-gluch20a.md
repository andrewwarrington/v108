---
title: Constructing a provably adversarially-robust classifier from a high accuracy
  one
abstract: Modern machine learning models with very high accuracy have been shown to
  be vulnerable to small, adversarially chosen perturbations of the input. Given black-box
  access to a high-accuracy classifier f, we show how to construct a new classifier
  g that has high accuracy and is also robust to adversarial L2-bounded perturbations.
  Our algorithm builds upon the framework of randomized smoothing that has been recently
  shown to outperform all previous defenses against L2-bounded adversaries. Using
  techniques like random partitions and doubling dimension, we are able to bound the
  adversarial error of g in terms of the optimum error. In this paper we focus on
  our conceptual contribution, but we do present two examples to illustrate our framework.
  We will argue that, under some assumptions, our bounds are optimal for these cases.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: gluch20a
month: 0
tex_title: Constructing a provably adversarially-robust classifier from a high accuracy
  one
firstpage: 3674
lastpage: 3684
page: 3674-3684
order: 3674
cycles: false
bibtex_author: Gluch, Grzegorz and Urbanke, R\"udiger
author:
- given: Grzegorz
  family: Gluch
- given: RÃ¼diger
  family: Urbanke
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/gluch20a/gluch20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/gluch20a/gluch20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
