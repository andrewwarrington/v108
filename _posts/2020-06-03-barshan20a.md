---
title: 'RelatIF: Identifying Explanatory Training Samples via Relative Influence'
abstract: In this work, we focus on the use of influence functions to identify relevant
  training examples that one might hope “explain” the predictions of a machine learning
  model. One shortcoming of influence functions is that the training examples deemed
  most “influential” are often outliers or mislabelled, making them poor choices for
  explanation. In order to address this shortcoming, we separate the role of global
  versus local influence. We introduce RelatIF, a new class of criteria for choosing
  relevant training examples by way of an optimization objective that places a constraint
  on global influence. RelatIF considers the local influence that an explanatory example
  has on a prediction relative to its global effects on the model. In empirical evaluations,
  we find that the examples returned by RelatIF are more intuitive when compared to
  those found using influence functions.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: barshan20a
month: 0
tex_title: 'RelatIF: Identifying Explanatory Training Samples via Relative Influence'
firstpage: 1899
lastpage: 1909
page: 1899-1909
order: 1899
cycles: false
bibtex_author: Barshan, Elnaz and Brunet, Marc-Etienne and Dziugaite, Gintare Karolina
author:
- given: Elnaz
  family: Barshan
- given: Marc-Etienne
  family: Brunet
- given: Gintare Karolina
  family: Dziugaite
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/barshan20a/barshan20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/barshan20a/barshan20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
