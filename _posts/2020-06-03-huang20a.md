---
title: Stochastic Neural Network with Kronecker Flow
abstract: Recent advances in variational inference enable the modelling of highly
  structured joint distributions, but are limited in their capacity to scale to the
  high-dimensional setting of stochastic neural networks. This limitation motivates
  a need for scalable parameterizations of the noise generation process, in a manner
  that adequately captures the dependencies among the various parameters.  In this
  work, we address this need and present the Kronecker Flow, a generalization of the
  Kronecker product to invertible mappings designed for stochastic neural networks.  We
  apply our method to variational Bayesian neural networks on predictive tasks, PAC-Bayes
  generalization bound estimation, and approximate Thompson sampling in contextual
  bandits. In all setups, our methods prove to be competitive with existing methods
  and betterthan the baselines.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: huang20a
month: 0
tex_title: Stochastic Neural Network with Kronecker Flow
firstpage: 4184
lastpage: 4194
page: 4184-4194
order: 4184
cycles: false
bibtex_author: Huang, Chin-Wei and Touati, Ahmed and Vincent, Pascal and Dziugaite,
  Gintare Karolina and Lacoste, Alexandre and Courville, Aaron
author:
- given: Chin-Wei
  family: Huang
- given: Ahmed
  family: Touati
- given: Pascal
  family: Vincent
- given: Gintare Karolina
  family: Dziugaite
- given: Alexandre
  family: Lacoste
- given: Aaron
  family: Courville
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/huang20a/huang20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/huang20a/huang20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
