---
title: Robust Learning from Discriminative Feature Feedback
abstract: Recent work introduced the model of "learning from discriminative feature
  feedback", in which a human annotator not only provides labels of instances, but
  also identifies discriminative features that highlight important differences between
  pairs of instances. It was shown that such feedback can be conducive to learning,
  and makes it possible to efficiently learn some concept classes that would otherwise
  be intractable. However, these results all relied upon *perfect* annotator feedback.
  In this paper, we introduce a more realistic, *robust* version of the framework,
  in which the annotator is allowed to make mistakes. We show how such errors can
  be handled algorithmically, in both an adversarial and a stochastic setting. In
  particular, we derive regret bounds in both settings that, as in the case of a perfect
  annotator, are independent of the number of features. We show that this result cannot
  be obtained by a naive reduction from the robust setting to the non-robust setting.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: dasgupta20a
month: 0
tex_title: Robust Learning from Discriminative Feature Feedback
firstpage: 973
lastpage: 982
page: 973-982
order: 973
cycles: false
bibtex_author: Dasgupta, Sanjoy and Sabato, Sivan
author:
- given: Sanjoy
  family: Dasgupta
- given: Sivan
  family: Sabato
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/dasgupta20a/dasgupta20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/dasgupta20a/dasgupta20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
