---
title: Bandit Convex Optimization in Non-stationary Environments
abstract: Bandit Convex Optimization (BCO) is a fundamental framework for modeling
  sequential decision-making with partial information, where the only feedback available
  to the player is the one-point or two-point function values. In this paper, we investigate
  BCO in non-stationary environments and choose the dynamic regret as the performance
  measure, which is defined as the difference between the cumulative loss incurred
  by the algorithm and that of any feasible comparator sequence. Let $T$ be the time
  horizon and $P_T$ be the path-length of the comparator sequence that reflects the
  non-stationarity of environments. We propose a novel algorithm that achieves $O(T^{3/4}(1+P_T)^{1/2})$
  and $O(T^{1/2}(1+P_T)^{1/2})$ dynamic regret respectively for the one-point and
  two-point feedback models. The latter result is optimal, matching the $\Omega(T^{1/2}(1+P_T)^{1/2})$
  lower bound established in this paper. Notably, our algorithm is more adaptive to
  non-stationary environments since it does not require prior knowledge of the path-length
  $P_T$ ahead of time, which is generally unknown.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: zhao20b
month: 0
tex_title: Bandit Convex Optimization in Non-stationary Environments
firstpage: 1508
lastpage: 1518
page: 1508-1518
order: 1508
cycles: false
bibtex_author: Zhao, Peng and Wang, Guanghui and Zhang, Lijun and Zhou, Zhi-Hua
author:
- given: Peng
  family: Zhao
- given: Guanghui
  family: Wang
- given: Lijun
  family: Zhang
- given: Zhi-Hua
  family: Zhou
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/zhao20b/zhao20b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
