---
title: Tensorized Random Projections
abstract: We introduce a novel random projection technique for efficiently reducing
  the dimension of very high-dimensional tensors. Building upon classical results
  on Gaussian random projections and Johnson-Lindenstrauss transforms (JLT), we propose
  two tensorized random projection maps relying on the tensor train (TT) and CP decomposition
  format, respectively. The two maps offer  very low  memory requirements and can
  be applied efficiently when the inputs are low rank tensors given in the CP or TT
  format.Our theoretical analysis shows that the dense Gaussian matrix in JLT can
  be replaced by a low-rank tensor implicitly represented in compressed form with
  random factors, while still approximately preserving the Euclidean distance of the
  projected inputs. In addition, our results reveal that the TT format is substantially
  superior to CP in terms of the size of the random projection needed to achieve the
  same distortion ratio. Experiments on synthetic data validate our theoretical analysis
  and demonstrate the superiority of the TT decomposition.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: rakhshan20a
month: 0
tex_title: Tensorized Random Projections
firstpage: 3306
lastpage: 3316
page: 3306-3316
order: 3306
cycles: false
bibtex_author: Rakhshan, Beheshteh and Rabusseau, Guillaume
author:
- given: Beheshteh
  family: Rakhshan
- given: Guillaume
  family: Rabusseau
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/rakhshan20a/rakhshan20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/rakhshan20a/rakhshan20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
