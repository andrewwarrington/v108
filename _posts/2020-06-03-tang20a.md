---
title: Variance Reduction for Evolution Strategies via Structured Control Variates
abstract: Evolution Strategies (ES) are a powerful class of blackbox optimization
  techniques that recently became a competitive alternative to state-of-the-art policy
  gradient (PG) algorithms for reinforcement learning (RL). We propose a new method
  for improving accuracy of the ES algorithms, that as opposed to recent approaches
  utilizing only Monte Carlo structure of the gradient estimator, takes advantage
  of the underlying MDP structure to reduce the variance. We observe that the gradient
  estimator of the ES objective can be alternatively computed using reparametrization
  and PG estimators, which leads to new control variate techniques for gradient estimation
  in ES optimization. We provide theoretical insights and show through extensive experiments
  that this RL-specific variance reduction approach outperforms general purpose variance
  reduction methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: tang20a
month: 0
tex_title: Variance Reduction for Evolution Strategies via Structured Control Variates
firstpage: 646
lastpage: 656
page: 646-656
order: 646
cycles: false
bibtex_author: Tang, Yunhao and Choromanski, Krzysztof and Kucukelbir, Alp
author:
- given: Yunhao
  family: Tang
- given: Krzysztof
  family: Choromanski
- given: Alp
  family: Kucukelbir
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/tang20a/tang20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/tang20a/tang20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
