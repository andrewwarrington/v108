---
title: Convergence Rates of Gradient Descent and MM Algorithms for Bradley-Terry Models
abstract: 'We present tight convergence rate bounds for gradient descent and MM algorithms
  for maximum likelihood (ML) estimation and maximum a posteriori probability (MAP)
  estimation of a popular Bayesian inference method, for Bradley-Terry models of ranking
  data. Our results show that MM algorithms have the same convergence rate, up to
  a constant factor, as gradient descent algorithms with optimal constant step size.
  For the ML estimation objective, the convergence is linear with the rate crucially
  determined by the algebraic connectivity of the matrix of item pair co-occurrences
  in observed comparison data. For the MAP estimation objective, we show that the
  convergence rate is also linear, with the rate determined by a parameter of the
  prior distribution in a way that can make convergence arbitrarily slow for small
  values of this parameter. The limit of small values of this parameter corresponds
  to a flat, non-informative prior distribution.  '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: vojnovic20a
month: 0
tex_title: Convergence Rates of Gradient Descent and MM Algorithms for Bradley-Terry
  Models
firstpage: 1254
lastpage: 1264
page: 1254-1264
order: 1254
cycles: false
bibtex_author: Vojnovic, Milan and Yun, Se-Young and Zhou, Kaifang
author:
- given: Milan
  family: Vojnovic
- given: Se-Young
  family: Yun
- given: Kaifang
  family: Zhou
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/vojnovic20a/vojnovic20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/vojnovic20a/vojnovic20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
