---
title: Adaptive Trade-Offs in Off-Policy Learning
abstract: 'A great variety of off-policy learning algorithms exist in the literature,
  and new breakthroughs in this area continue to be made, improving theoretical understanding
  and yielding state-of-the-art reinforcement learning algorithms. In this paper,
  we take a unifying view of this space of algorithms, and consider their trade-offs
  of three fundamental quantities: update variance, fixed-point bias, and contraction
  rate. This leads to new perspectives on existing methods, and also naturally yields
  novel algorithms for off-policy evaluation and control. We develop one such algorithm,
  C-trace, demonstrating that it is able to more efficiently make these trade-offs
  than existing methods in use, and that it can be scaled to yield state-of-the-art
  performance in large-scale environments.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: rowland20a
month: 0
tex_title: Adaptive Trade-Offs in Off-Policy Learning
firstpage: 34
lastpage: 44
page: 34-44
order: 34
cycles: false
bibtex_author: Rowland, Mark and Dabney, Will and Munos, Remi
author:
- given: Mark
  family: Rowland
- given: Will
  family: Dabney
- given: Remi
  family: Munos
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/rowland20a/rowland20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/rowland20a/rowland20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
