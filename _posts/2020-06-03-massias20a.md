---
title: Support recovery and sup-norm convergence rates for sparse pivotal estimation
abstract: In high dimensional sparse regression, pivotal estimators are estimators
  for which the optimal regularization parameter is independent of the noise level.
  The canonical pivotal estimator is the square-root Lasso, formulated along with
  its derivatives as a “non-smooth + non-smooth” optimization problem. Modern techniques
  to solve these include smoothing the datafitting term, to benefit from fast efficient
  proximal algorithms. In this work we show minimax sup-norm convergence rates for
  non smoothed and smoothed, single task and multitask square-root Lasso-type estimators.
  Thanks to our theoretical analysis, we provide some guidelines on how to set the
  smoothing hyperparameter, and illustrate on synthetic data the interest of such
  guidelines.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: massias20a
month: 0
tex_title: Support recovery and sup-norm convergence rates for sparse pivotal estimation
firstpage: 2655
lastpage: 2665
page: 2655-2665
order: 2655
cycles: false
bibtex_author: Massias, Mathurin and Bertrand, Quentin and Gramfort, Alexandre and
  Salmon, Joseph
author:
- given: Mathurin
  family: Massias
- given: Quentin
  family: Bertrand
- given: Alexandre
  family: Gramfort
- given: Joseph
  family: Salmon
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/massias20a/massias20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/massias20a/massias20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
