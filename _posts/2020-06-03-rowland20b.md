---
title: Conditional Importance Sampling for Off-Policy Learning
abstract: The principal contribution of this paper is a conceptual framework for off-policy
  reinforcement learning, based on conditional expectations of importance sampling
  ratios. This framework yields new perspectives and understanding of existing off-policy
  algorithms, and reveals a broad space of unexplored algorithms. We theoretically
  analyse this space, and concretely investigate several algorithms that arise from
  this framework.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: rowland20b
month: 0
tex_title: Conditional Importance Sampling for Off-Policy Learning
firstpage: 45
lastpage: 55
page: 45-55
order: 45
cycles: false
bibtex_author: Rowland, Mark and Harutyunyan, Anna and van Hasselt, Hado and Borsa,
  Diana and Schaul, Tom and Munos, Remi and Dabney, Will
author:
- given: Mark
  family: Rowland
- given: Anna
  family: Harutyunyan
- given: Hado
  family: Hasselt
- given: Diana
  family: Borsa
- given: Tom
  family: Schaul
- given: Remi
  family: Munos
- given: Will
  family: Dabney
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/rowland20b/rowland20b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/rowland20b/rowland20b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
