---
title: Formal Limitations on the Measurement of Mutual Information
abstract: Measuring mutual information from finite data is difficult. Recent work
  has considered variational methods maximizing a lower bound. In this paper, we prove
  that serious statistical limitations are inherent to any method of measuring mutual
  information. More specifically, we show that any distribution-free high-confidence
  lower bound on mutual information estimated from N samples cannot be larger than
  O(ln N).
layout: inproceedings
series: Proceedings of Machine Learning Research
id: mcallester20a
month: 0
tex_title: Formal Limitations on the Measurement of Mutual Information
firstpage: 875
lastpage: 884
page: 875-884
order: 875
cycles: false
bibtex_author: McAllester, David and Stratos, Karl
author:
- given: David
  family: McAllester
- given: Karl
  family: Stratos
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/mcallester20a/mcallester20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/mcallester20a/mcallester20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
