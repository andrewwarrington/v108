---
title: Sublinear Optimal Policy Value Estimation in Contextual Bandits
abstract: 'We study the problem of estimating the expected reward of the optimal policy
  in the stochastic disjoint linear bandit setting. We prove that for certain settings
  it is possible to obtain an accurate estimate of the optimal policy value even with
  a sublinear number of samples, where a linear set would be needed to reliably estimate
  the reward that can be obtained by any policy. We establish near matching information
  theoretic lower bounds, showing that our algorithm achieves near optimal estimation
  error. Finally, we demonstrate the effectiveness of our algorithm on joke recommendation
  and cancer inhibition dosage selection problems using real datasets. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: kong20b
month: 0
tex_title: Sublinear Optimal Policy Value Estimation in Contextual Bandits
firstpage: 4377
lastpage: 4387
page: 4377-4387
order: 4377
cycles: false
bibtex_author: Kong, Weihao and Brunskill, Emma and Valiant, Gregory
author:
- given: Weihao
  family: Kong
- given: Emma
  family: Brunskill
- given: Gregory
  family: Valiant
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/kong20b/kong20b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/kong20b/kong20b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
