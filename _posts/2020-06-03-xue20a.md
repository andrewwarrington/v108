---
title: Auditing ML Models for Individual Bias and Unfairness
abstract: We consider the task of auditing ML models for individual bias/unfairness.
  We formalize the task in an optimization problem and develop a suite of inferential
  tools for the optimal value. Our tools permit us to obtain asymptotic confidence
  intervals and hypothesis tests that cover the target/control the Type I error rate
  exactly. To demonstrate the utility of our tools, we use them to reveal the gender
  and racial biases in Northpointeâ€™s COMPAS recidivism prediction instrument.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: xue20a
month: 0
tex_title: Auditing ML Models for Individual Bias and Unfairness
firstpage: 4552
lastpage: 4562
page: 4552-4562
order: 4552
cycles: false
bibtex_author: Xue, Songkai and Yurochkin, Mikhail and Sun, Yuekai
author:
- given: Songkai
  family: Xue
- given: Mikhail
  family: Yurochkin
- given: Yuekai
  family: Sun
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/xue20a/xue20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/xue20a/xue20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
