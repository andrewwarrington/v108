---
title: Competing Bandits in Matching Markets
abstract: 'Stable matching, a classical model for two-sided markets, has long been
  studied assuming known preferences. In reality agents often have to learn about
  their preferences through exploration. With the advent of massive online markets
  powered by data-driven matching platforms, it has become necessary to better understand
  the interplay between learning and market objectives. We propose a statistical learning
  model in which one side of the market does not have a priori knowledge about its
  preferences for the other side and is required to learn these from stochastic rewards.
  Our model extends the standard multi-armed bandits framework to multiple players,
  with the added feature that arms have preferences over players. We study both centralized
  and decentralized approaches to this problem and show surprising exploration-exploitation
  trade-offs compared to the single player multi-armed bandits setting. '
layout: inproceedings
series: Proceedings of Machine Learning Research
id: liu20c
month: 0
tex_title: Competing Bandits in Matching Markets
firstpage: 1618
lastpage: 1628
page: 1618-1628
order: 1618
cycles: false
bibtex_author: Liu, Lydia T. and Mania, Horia and Jordan, Michael
author:
- given: Lydia T.
  family: Liu
- given: Horia
  family: Mania
- given: Michael
  family: Jordan
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/liu20c/liu20c.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/liu20c/liu20c-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
