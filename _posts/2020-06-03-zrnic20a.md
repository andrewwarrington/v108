---
title: The Power of Batching in Multiple Hypothesis Testing
abstract: One important partition of algorithms for controlling the false discovery
  rate (FDR) in multiple testing is into offline and online algorithms. The first
  generally achieve significantly higher power of discovery, while the latter allow
  making decisions sequentially as well as adaptively formulating hypotheses based
  on past observations. Using existing methodology, it is unclear how one could trade
  off the benefits of these two broad families of algorithms, all the while preserving
  their formal FDR guarantees. To this end, we introduce Batch-BH and Batch-St-BH,
  algorithms for controlling the FDR when a possibly infinite sequence of batches
  of hypotheses is tested by repeated application of one of the most widely used offline
  algorithms, the Benjamini-Hochberg (BH) method or Storeyâ€™s improvement of the BH
  method. We show that our algorithms interpolate between existing online and offline
  methodology, thus trading off the best of both worlds.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: zrnic20a
month: 0
tex_title: The Power of Batching in Multiple Hypothesis Testing
firstpage: 3806
lastpage: 3815
page: 3806-3815
order: 3806
cycles: false
bibtex_author: Zrnic, Tijana and Jiang, Daniel and Ramdas, Aaditya and Jordan, Michael
author:
- given: Tijana
  family: Zrnic
- given: Daniel
  family: Jiang
- given: Aaditya
  family: Ramdas
- given: Michael
  family: Jordan
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/zrnic20a/zrnic20a.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v108/zrnic20a/zrnic20a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
