---
title: Thresholding Bandit Problem with Both Duels and Pulls
abstract: The Thresholding Bandit Problem (TBP) aims to find the set of arms with
  mean rewards greater than a given threshold. We consider a new setting of TBP, where
  in addition to pulling arms, one can also duel two arms and get the arm with a greater
  mean. In our motivating application from crowdsourcing,  dueling two arms can be
  more cost-effective and time-efficient than direct pulls. We refer to this problem
  as TBP with Dueling Choices (TBP-DC). This paper provides an algorithm called Rank-Search
  (RS) for solving TBP-DC by alternating between ranking and binary search. We prove
  theoretical guarantees for RS, and also give lower bounds to show the optimality
  of it. Experiments show that RS outperforms previous baseline algorithms that only
  use pulls or duels.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: xu20c
month: 0
tex_title: Thresholding Bandit Problem with Both Duels and Pulls
firstpage: 2591
lastpage: 2600
page: 2591-2600
order: 2591
cycles: false
bibtex_author: Xu, Yichong and Chen, Xi and Singh, Aarti and Dubrawski, Artur
author:
- given: Yichong
  family: Xu
- given: Xi
  family: Chen
- given: Aarti
  family: Singh
- given: Artur
  family: Dubrawski
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/xu20c/xu20c.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/xu20c/xu20c-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
