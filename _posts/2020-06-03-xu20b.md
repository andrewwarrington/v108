---
title: Accelerated Primal-Dual Algorithms for Distributed Smooth Convex Optimization
  over Networks
abstract: This paper proposes a novel family of primal-dual-based distributed algorithms
  for smooth, convex, multi-agent optimization over networks that uses only gradient
  information and gossip communications.  The algorithms can also employ acceleration
  on the computation and communications.  We provide a unified analysis of their convergence
  rate, measured in terms of the Bregman distance associated to the saddle point reformation
  of the distributed optimization problem.  When acceleration is employed, the rate
  is shown to be optimal, in the sense that it matches (under the proposed metric)
  existing complexity lower bounds of distributed algorithms applicable to such a
  class of problem and using only gradient information and gossip communications.  Preliminary
  numerical results on distributed least-square regression problems show that the
  proposed algorithm compares favorably on existing distributed schemes.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: xu20b
month: 0
tex_title: Accelerated Primal-Dual Algorithms for Distributed Smooth Convex Optimization
  over Networks
firstpage: 2381
lastpage: 2391
page: 2381-2391
order: 2381
cycles: false
bibtex_author: Xu, Jinming and Tian, Ye and Sun, Ying and Scutari, Gesualdo
author:
- given: Jinming
  family: Xu
- given: Ye
  family: Tian
- given: Ying
  family: Sun
- given: Gesualdo
  family: Scutari
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/xu20b/xu20b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/xu20b/xu20b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
