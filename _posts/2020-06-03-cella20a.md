---
title: Stochastic Bandits with Delay-Dependent Payoffs
abstract: Motivated by recommendation problems in music streaming platforms, we propose
  a nonstationary stochastic bandit model in which the expected reward of an arm depends
  on the number of rounds that have passed since the arm was last pulled. After proving
  that finding an optimal policy is NP-hard even when all model parameters are known,
  we introduce a class of ranking policies provably approximating, to within a constant
  factor, the expected reward of the optimal policy. We show an algorithm whose regret
  with respect to the best ranking policy is bounded by $\widetilde{\scO}\big(\!\sqrt{kT}\big)$,
  where $k$ is the number of arms and $T$ is time. Our algorithm uses only $\scO\big(k\ln\ln
  T)$ switches, which helps when switching between policies is costly. As constructing
  the class of learning policies requires ordering the arms according to their expectations,
  we also bound the number of pulls required to do so. Finally, we run experiments
  to compare our algorithm against UCB on different problem instances.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: cella20a
month: 0
tex_title: Stochastic Bandits with Delay-Dependent Payoffs
firstpage: 1168
lastpage: 1177
page: 1168-1177
order: 1168
cycles: false
bibtex_author: Cella, Leonardo and Cesa-Bianchi, Nicol\'o
author:
- given: Leonardo
  family: Cella
- given: Nicol√≥
  family: Cesa-Bianchi
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/cella20a/cella20a.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v108/cella20a/cella20a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
