---
title: 'Feature relevance quantification in explainable AI: A causal problem'
abstract: We discuss promising recent contributions on quantifying feature relevance
  using Shapley values, where we observed some confusion on which probability distribution
  is the right one for dropped features. We argue that the confusion is based on not
  carefully distinguishing between observational and interventional conditional probabilities
  and try a clarification based on Pearl’s seminal work on causality. We conclude
  that unconditional rather than conditional expectations provide the right notion
  of dropping features. This contradicts the view of the authors of the software package
  SHAP. In that work, unconditional expectations (which we argue to be conceptually
  right) are only used as approximation for the conditional ones, which encouraged
  others to ’improve’ SHAP in a way that we believe to be flawed.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: janzing20a
month: 0
tex_title: 'Feature relevance quantification in explainable AI: A causal problem'
firstpage: 2907
lastpage: 2916
page: 2907-2916
order: 2907
cycles: false
bibtex_author: Janzing, Dominik and Minorics, Lenon and Bloebaum, Patrick
author:
- given: Dominik
  family: Janzing
- given: Lenon
  family: Minorics
- given: Patrick
  family: Bloebaum
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/janzing20a/janzing20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
