---
title: A Continuous-time Perspective for Modeling Acceleration in Riemannian Optimization
abstract: We propose a novel second-order ODE as the continuous-time limit of a Riemannian
  accelerated gradient-based method on a manifold with curvature bounded from below.
  This ODE can be seen as a generalization of the  ODE derived for Euclidean spaces,
  and can also serve as an analysis tool. We analyze the convergence behavior of this
  ODE for different types of functions, such as geodesically convex, strongly-convex
  and weakly-quasi-convex. We demonstrate how such an ODE can be discretized using
  a semi-implicit and Nesterov-inspired numerical integrator, that empirically yields
  stable algorithms which are faithful to the continuous-time analysis and exhibit
  accelerated convergence.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: alimisis20a
month: 0
tex_title: A Continuous-time Perspective for Modeling Acceleration in Riemannian Optimization
firstpage: 1297
lastpage: 1307
page: 1297-1307
order: 1297
cycles: false
bibtex_author: Alimisis, Foivos and Orvieto, Antonio and Becigneul, Gary and Lucchi,
  Aurelien
author:
- given: Foivos
  family: Alimisis
- given: Antonio
  family: Orvieto
- given: Gary
  family: Becigneul
- given: Aurelien
  family: Lucchi
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/alimisis20a/alimisis20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/alimisis20a/alimisis20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
