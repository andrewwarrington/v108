---
title: Momentum in Reinforcement Learning
abstract: We adapt the optimizationâ€™s concept of momentum to reinforcement learning.
  Seeing the state-action value functions as an anlog to the gradients in optimization,
  we interpret momentum as an average of consecutive $q$-functions. We derive Momentum
  Value Iteration (MoVI), a variation of Value iteration that incorporates this momentum
  idea. Our analysis shows that this allows MoVI to average errors over successive
  iterations. We show that the proposed approach can be readily extended to deep learning.
  Specifically,we propose a simple improvement on DQN based on MoVI, and experiment
  it on Atari games.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: vieillard20a
month: 0
tex_title: Momentum in Reinforcement Learning
firstpage: 2529
lastpage: 2538
page: 2529-2538
order: 2529
cycles: false
bibtex_author: Vieillard, Nino and Scherrer, Bruno and Pietquin, Olivier and Geist,
  Matthieu
author:
- given: Nino
  family: Vieillard
- given: Bruno
  family: Scherrer
- given: Olivier
  family: Pietquin
- given: Matthieu
  family: Geist
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/vieillard20a/vieillard20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/vieillard20a/vieillard20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
