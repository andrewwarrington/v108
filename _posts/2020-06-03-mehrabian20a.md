---
title: A Practical Algorithm for Multiplayer Bandits when Arm Means Vary Among Players
abstract: We study a multiplayer stochastic multi-armed bandit problem in which players
  cannot communicate, and if two or more players pull the same arm, a collision occurs
  and the involved players receive zero reward. We consider the challenging heterogeneous
  setting, in which different arms may have different means for different players,
  and propose a new and efficient algorithm that combines the idea of leveraging forced
  collisions for implicit communication and that of performing matching eliminations.
  We present a finite-time analysis of our algorithm, giving the first sublinear minimax
  regret bound for this problem, and prove that if the optimal assignment of players
  to arms is unique, our algorithm attains the optimal O(ln(T)) regret, solving an
  open question raised at NeurIPS 2018 by Bistritz and Leshem (2018).
layout: inproceedings
series: Proceedings of Machine Learning Research
id: mehrabian20a
month: 0
tex_title: A Practical Algorithm for Multiplayer Bandits when Arm Means Vary Among
  Players
firstpage: 1211
lastpage: 1221
page: 1211-1221
order: 1211
cycles: false
bibtex_author: Mehrabian, Abbas and Boursier, Etienne and Kaufmann, Emilie and Perchet,
  Vianney
author:
- given: Abbas
  family: Mehrabian
- given: Etienne
  family: Boursier
- given: Emilie
  family: Kaufmann
- given: Vianney
  family: Perchet
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/mehrabian20a/mehrabian20a.pdf
extras:
- label: Supplementary ZIP
  link: http://proceedings.mlr.press/v108/mehrabian20a/mehrabian20a-supp.zip
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
