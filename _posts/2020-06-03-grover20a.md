---
title: Bayesian Reinforcement Learning via Deep, Sparse Sampling
abstract: " We address the problem of Bayesian reinforcement learning using efficient
  model-based online planning. We propose an optimism-free Bayes-adaptive algorithm
  to induce deeper and sparser exploration with a theoretical bound on its performance
  relative to the Bayes optimal as well as lower computational complexity. The main
  novelty is the use of a candidate policy generator, to generate long-term options
  in the planning tree (over beliefs), which allows us to create much sparser and
  deeper trees. Experimental results on different environments show that in comparison
  to the state-of-the-art, our algorithm is both computationally more efficient, and
  obtains significantly higher reward over time in discrete environments."
layout: inproceedings
series: Proceedings of Machine Learning Research
id: grover20a
month: 0
tex_title: Bayesian Reinforcement Learning via Deep, Sparse Sampling
firstpage: 3036
lastpage: 3045
page: 3036-3045
order: 3036
cycles: false
bibtex_author: Grover, Divya and Basu, Debabrota and Dimitrakakis, Christos
author:
- given: Divya
  family: Grover
- given: Debabrota
  family: Basu
- given: Christos
  family: Dimitrakakis
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/grover20a/grover20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/grover20a/grover20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
