---
title: Entropy Weighted Power k-Means Clustering
abstract: Despite its well-known shortcomings, k-means remains one of the most widely
  used approaches to data clustering. Current research continues to tackle its flaws
  while attempting to preserve its simplicity. Recently, the power k-means algorithm
  was proposed to avoid poor local minima by annealing through a family of smoother
  surfaces. However,  the approach lacks statistical guarantees and fails in high
  dimensions when many features are irrelevant. This paper addresses these issues
  by introducing entropy regularization to learn feature relevance while annealing.
  We prove consistency of the proposed approach and derive a scalable majorization-minimization
  algorithm that enjoys closed-form updates and convergence guarantees. In particular,
  our method retains the same computational complexity of k-means and power k-means,
  but yields significant improvements over both. Its merits are thoroughly assessed
  on a suite of real and synthetic data.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: chakraborty20a
month: 0
tex_title: Entropy Weighted Power k-Means Clustering
firstpage: 691
lastpage: 701
page: 691-701
order: 691
cycles: false
bibtex_author: Chakraborty, Saptarshi and Paul, Debolina and Das, Swagatam and Xu,
  Jason
author:
- given: Saptarshi
  family: Chakraborty
- given: Debolina
  family: Paul
- given: Swagatam
  family: Das
- given: Jason
  family: Xu
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/chakraborty20a/chakraborty20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/chakraborty20a/chakraborty20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
