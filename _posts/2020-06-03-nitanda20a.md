---
title: Functional Gradient Boosting for Learning Residual-like Networks with Statistical
  Guarantees
abstract: Recently, several studies have proposed progressive or sequential layer-wise
  training methods based on the boosting theory for deep neural networks. However,
  most studies lack the global convergence guarantees or require weak learning conditions
  that can be verified a posteriori after running methods. Moreover, generalization
  bounds usually have a worse dependence on network depth. In this paper, to resolve
  these problems, we propose a new functional gradient boosting for learning deep
  residual-like networks in a layer-wise fashion with its statistical guarantees on
  multi-class classification tasks. In the proposed method, each residual block is
  recognized as a functional gradient (i.e., weak learner), and the functional gradient
  step is performed by stacking it on the network, resulting in a strong optimization
  ability. In the theoretical analysis, we show the global convergence of the method
  under a standard margin assumption on a data distribution instead of a weak learning
  condition, and we eliminate a worse dependence on the network depth in a generalization
  bound via a fine-grained convergence analysis. %, unlike existing studies. Moreover,
  we show that the existence of a learnable function with a large margin on a training
  dataset significantly improves a generalization bound. Finally, we experimentally
  demonstrate that our proposed method is certainly useful for learning deep residual
  networks.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: nitanda20a
month: 0
tex_title: Functional Gradient Boosting for Learning Residual-like Networks with Statistical
  Guarantees
firstpage: 2981
lastpage: 2991
page: 2981-2991
order: 2981
cycles: false
bibtex_author: Nitanda, Atsushi and Suzuki, Taiji
author:
- given: Atsushi
  family: Nitanda
- given: Taiji
  family: Suzuki
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/nitanda20a/nitanda20a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/nitanda20a/nitanda20a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
