---
title: Sparse Orthogonal Variational Inference for Gaussian Processes
abstract: 'We introduce a new interpretation of sparse variational approximations
  for Gaussian processes using inducing points, which can lead to more scalable algorithms
  than previous methods. It is based on decomposing a Gaussian process as a sum of
  two independent processes: one spanned by a finite basis of inducing points and
  the other capturing the remaining variation. We show that this formulation recovers
  existing approximations and at the same time allows to obtain tighter lower bounds
  on the marginal likelihood and new stochastic variational inference algorithms.
  We demonstrate the efficiency of these algorithms in several Gaussian process models
  ranging from standard regression to multi-class classification using (deep) convolutional
  Gaussian processes and report state-of-the-art results on CIFAR-10 among purely
  GP-based models.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: shi20b
month: 0
tex_title: Sparse Orthogonal Variational Inference for Gaussian Processes
firstpage: 1932
lastpage: 1942
page: 1932-1942
order: 1932
cycles: false
bibtex_author: Shi, Jiaxin and Titsias, Michalis and Mnih, Andriy
author:
- given: Jiaxin
  family: Shi
- given: Michalis
  family: Titsias
- given: Andriy
  family: Mnih
date: 2020-06-03
address: 
publisher: PMLR
container-title: Proceedings of the Twenty Third International Conference on Artificial
  Intelligence and Statistics
volume: '108'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 6
  - 3
pdf: http://proceedings.mlr.press/v108/shi20b/shi20b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v108/shi20b/shi20b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
